{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "muslim-ivory",
   "metadata": {},
   "source": [
    "The avg. runtime of `retrive_and_interpolate_data` and save a new dataframe is 6.5s for each entry in the csv\n",
    "\n",
    "Therefore the runtime of 4160 entries in 2016_AIS.csv is approximatly `7.5` hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-sacrifice",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T15:51:07.863400Z",
     "start_time": "2021-02-15T15:51:06.867287Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "from motu_utils.utils_cas import authenticate_CAS_for_URL\n",
    "from motu_utils.utils_http import open_url\n",
    "import xarray as xr\n",
    "from datetime import datetime, timezone, timedelta \n",
    "import time\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-beginning",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T15:51:10.409385Z",
     "start_time": "2021-02-15T15:51:10.402772Z"
    }
   },
   "outputs": [],
   "source": [
    "# url without variables\n",
    "base_url = 'http://nrt.cmems-du.eu/motu-web/Motu?action=productdownload&service=GLOBAL_ANALYSIS_FORECAST_WAV_001_027-TDS&product=global-analysis-forecast-wav-001-027'\n",
    "\n",
    "# utils to convert dates \n",
    "str_to_date = lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n",
    "date_to_str = lambda x: x.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "# credentials for the dataset\n",
    "UN_CMEMS = %env UN_CMEMS\n",
    "PW_CMEMS = %env PW_CMEMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-execution",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T15:51:22.419995Z",
     "start_time": "2021-02-15T15:51:22.411021Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_request_url(date, lat, lon):\n",
    "    \"\"\"\n",
    "        creates a valid url to download data from the dataset with using credentials.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    date : str\n",
    "        datetime as a string as the format YYYY-mm-ddTHH:MM:SSZ\n",
    "    lat : str, float\n",
    "        latitude\n",
    "    lon : str, float\n",
    "        longitude\n",
    "    \"\"\"\n",
    "    y_lo=float(lat)\n",
    "    y_hi=float(lat)\n",
    "    x_lo=float(lon)\n",
    "    x_hi=float(lon)\n",
    "    t_lo=date\n",
    "    t_hi=date\n",
    "    url = base_url+'&x_lo={0}&x_hi={1}&y_lo={2}&y_hi={3}&t_lo={4}&t_hi={5}&mode=console'.format(x_lo, x_hi, y_lo, y_hi, t_lo, t_hi)\n",
    "    return authenticate_CAS_for_URL(url , UN_CMEMS, PW_CMEMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-discharge",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T15:51:24.458171Z",
     "start_time": "2021-02-15T15:51:24.443212Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def retrive_and_interpolate_data(date, lat, lon, dataset_temporal_resolution):\n",
    "    \"\"\"\n",
    "        retrive all variables from dataset for a specific timestamp, latitude, longitude concidering\n",
    "        the temporal resolution of the dataset to calculate interpolated values\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    date : datetime object\n",
    "        datetime as a date object\n",
    "    lat : str, float\n",
    "        latitude\n",
    "    lon : str, float\n",
    "        longitude\n",
    "    dataset_temporal_resolution: int\n",
    "        the temporal resolution of the dateset (in hours)\n",
    "    \"\"\"\n",
    "    h = date.hour \n",
    "    rest = h % dataset_temporal_resolution \n",
    "    if rest == 0:\n",
    "        url = create_request_url(date_to_str(date), lat, lon)\n",
    "        date = xr.open_dataset(open_url(url).read())\n",
    "        return np.ravel(date.to_dataframe().reset_index(drop=True).values)\n",
    "    else:\n",
    "        nearest_lower = date - timedelta(hours= rest)\n",
    "        nearest_upper = date + timedelta(hours=dataset_temporal_resolution-rest)\n",
    "        \n",
    "        url_lower = create_request_url(date_to_str(nearest_lower), lat, lon)\n",
    "        url_upper = create_request_url(date_to_str(nearest_upper), lat, lon)\n",
    "        \n",
    "        bytes_lower = open_url(url_lower).read()\n",
    "        bytes_upper = open_url(url_upper).read()\n",
    "        \n",
    "        try:\n",
    "            data_lower = xr.open_dataset(bytes_lower)\n",
    "            data_upper = xr.open_dataset(bytes_upper) \n",
    "        except:\n",
    "            # print the error tag from html\n",
    "            print(BeautifulSoup(bytes_lower, 'html.parser').find('p', {\"class\": \"error\"}))\n",
    "            print(BeautifulSoup(bytes_upper, 'html.parser').find('p', {\"class\": \"error\"}))\n",
    "       \n",
    "      \n",
    "        v_lower = data_lower.to_dataframe().reset_index(drop=True)\n",
    "        v_upper = data_upper.to_dataframe().reset_index(drop=True)\n",
    "    \n",
    "        # temporal interpolation \n",
    "        alpha = rest / dataset_temporal_resolution\n",
    "        return np.ravel((1- alpha)* v_lower.values + (alpha * v_upper.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-hungary",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T15:58:03.405591Z",
     "start_time": "2021-02-15T15:58:03.394624Z"
    }
   },
   "outputs": [],
   "source": [
    "def append_enviorment_data(year):\n",
    "    src_csv_path = Path(str(year),'%s_AIS.csv' % year)\n",
    "    output_csv_path = Path(str(year),'%s_merged.csv' % year)\n",
    "    \n",
    "    # get extracted AIS data and remove index column\n",
    "    df = pd.read_csv(src_csv_path,parse_dates=['BaseDateTime'], date_parser=str_to_date)\n",
    "    df.drop(['Unnamed: 0'], axis=1, errors='ignore', inplace=True)\n",
    "    \n",
    "    # define a new columns for the output datafarme\n",
    "    cols = list(df.columns) + ['VHM0_WW', 'VMDR_SW2', 'VMDR_SW1','VMDR',  'VTM10', 'VTPK','VPED','VTM02','VMDR_WW','VTM01_SW2','VHM0_SW1','VTM01_SW1','VSDX','VSDY','VHM0','VTM01_WW','VHM0_SW2']\n",
    "   \n",
    "    # check if already appended data to resume in case of disconnetion or other errors\n",
    "    data_list = []\n",
    "    if Path(output_csv_path).exists():\n",
    "        data_list = list(pd.read_csv(output_csv_path).drop(['Unnamed: 0'], axis=1, errors='ignore').values)\n",
    "        print('Resuming download from row %s ' % len(data_list))\n",
    "        \n",
    "    # loop over the AIS data starting from the last index, where it has stopped\n",
    "    last_index = len(data_list)\n",
    "    for x in df.values[last_index:]:\n",
    "        date, lat, lon = x[:3]\n",
    "        env_variables = retrive_and_interpolate_data(date, lat, lon, 3)\n",
    "        data_list.append(np.concatenate([x, env_variables]))\n",
    "        pd.DataFrame(data_list, columns=cols).to_csv(output_csv_path)\n",
    "        last_index+=1\n",
    "        sys.stdout.write(\"\\rEntry row index: %s/%s\" % (last_index, len(df)))\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "    return pd.DataFrame(data_list, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-memorial",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T15:58:18.072743Z",
     "start_time": "2021-02-15T15:58:05.097994Z"
    }
   },
   "outputs": [],
   "source": [
    "result = append_enviorment_data(2016)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
