{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "upset-district",
   "metadata": {},
   "source": [
    "This notebook is used for downloading, extracting, and subsampling the Automatic Identification System (AIS) data, or Vessel traffic data, which are collected by the U.S. Coast Guard through an onboard navigation https://marinecadastre.gov/AIS/. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distant-diana",
   "metadata": {},
   "source": [
    "The year data is divided into UTMZoneMap https://marinecadastre.gov/AIS/AIS%20Documents/UTMZoneMap2014.png.\n",
    "The data is provided for years 2009-2020 divided into 19 UTM Zones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-porcelain",
   "metadata": {},
   "source": [
    "For more information about specifc parameters:\n",
    "https://help.marinetraffic.com/hc/en-us/articles/205426887-What-kind-of-information-is-AIS-transmitted-\n",
    "\n",
    "VesselType: Passenger, Cargo, Tanker, etc.\n",
    "https://help.marinetraffic.com/hc/en-us/articles/205579997-What-is-the-significance-of-the-AIS-Shiptype-number-\n",
    "https://coast.noaa.gov/data/marinecadastre/ais/VesselTypeCodes2018.pdf\n",
    "\n",
    "Status Values: sailing, moored etc..\n",
    "https://help.marinetraffic.com/hc/en-us/articles/203990998-What-is-the-significance-of-the-AIS-Navigational-Status-Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-tract",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import os\n",
    "import pandas as pd \n",
    "from os import walk\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-alloy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dir(year):\n",
    "    history =[]\n",
    "    for path, dirs, files in os.walk(str(year)):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv'):\n",
    "                history.append(file.split('.')[0])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-intro",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_AIS(year, zones):\n",
    "    Path(str(year)).mkdir(parents=True, exist_ok=True)\n",
    "    resume_download = check_dir(str(year))\n",
    "    url = \"https://coast.noaa.gov/htdata/CMSP/AISDataHandler/{0}/\".format(year)\n",
    "    html_text = requests.get(url).text\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "    files = []\n",
    "    for a in soup.find_all('a', href=True):\n",
    "         if a.text and a.text.endswith('zip'):\n",
    "            name, _ = a['href'].split('.')\n",
    "            l = name.split('_')\n",
    "            l.append(a.text)\n",
    "            files.append(l) \n",
    "\n",
    "    df = pd.DataFrame(files)\n",
    "    df.columns = [*df.columns[:-1], 'Files']\n",
    "  \n",
    "    for c in df.columns:\n",
    "        if c == 'Files': continue\n",
    "        unique_col = len(df[c].unique())\n",
    "        if unique_col == 12 or unique_col == 6: # some years provid data only for 6 month\n",
    "            df['Month'] = df[c]\n",
    "        elif unique_col == 31:\n",
    "            df['Days'] = df[c]\n",
    "        elif 20 >= unique_col >= 18 or 'zone' in df[c][0].lower():\n",
    "            if 'zone' in df[c][0].lower():\n",
    "                df['Zone'] = pd.to_numeric([z[z.lower().find('zone')+4:]for z in df[c]])\n",
    "            else:\n",
    "                df['Zone'] = pd.to_numeric(df[c])\n",
    "        del df[c]\n",
    "    \n",
    "    #  download\n",
    "    if 'Zone' in df.columns:\n",
    "        dl = df[df['Zone'].isin(zones)][['Files','Zone']]\n",
    "    else:\n",
    "        dl = df[['Files','Month']]\n",
    "    for file, zone in tqdm(dl.values.tolist()):\n",
    "        output = '%s_%s' % (year, str(zone))\n",
    "        Path(str(year)).joinpath(output).mkdir(parents=True, exist_ok=True)\n",
    "        if file.split('.')[0] in resume_download: continue\n",
    "        print(file)\n",
    "        wget.download(os.path.join(url,file)) \n",
    "        with zipfile.ZipFile(file, 'r') as zip_ref:\n",
    "            zip_ref.extractall(os.path.join(str(year), output))\n",
    "        os.remove(file)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-smart",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dates(date): \n",
    "    date = date.replace(second=0)\n",
    "    if date.minute > 45:\n",
    "        return date + timedelta(hours=0, minutes=(60-date.minute))  \n",
    "    else:\n",
    "        return date - timedelta(hours=0, minutes=date.minute)  \n",
    "   \n",
    "    \n",
    "    \n",
    "def subset_AIS_to_CSV(year, min_time_interval = 60):\n",
    "    data_list = []\n",
    "    for path, dirs, files in os.walk(str(year)):\n",
    "        for file in files:\n",
    "                if file.endswith('.csv'):\n",
    "                    x = os.path.join(path, file)\n",
    "                    print(x)\n",
    "                    df = pd.read_csv(x)\n",
    "                    df = df.drop(['MMSI', 'VesselName', 'CallSign', 'Cargo', 'TranscieverClass'], axis=1, errors='ignore')\n",
    "                    df = df.dropna()\n",
    "                    df = df.query('(Status == \"under way using engine\" or Status == \"under way sailing\" or  Status == 8 or  Status == 0) & (VesselType == 1016 or 79 >= VesselType >= 70) & SOG > 3 & Length > 3 & Width > 3 & Draft > 3 ')\n",
    "                    \n",
    "                    # parse and normalize utc time \n",
    "                    df['BaseDateTime'] = pd.to_datetime(df.BaseDateTime, format='%Y-%m-%dT%H:%M:%S').apply(normalize_dates) # 2017-01-01T01:30:10\n",
    "                    df.index = df.BaseDateTime\n",
    "                    df = df.resample(\"%dT\" % min_time_interval).last()\n",
    "                    data_list.extend(df.values)\n",
    "             \n",
    "    df = pd.DataFrame(data_list, columns=['BaseDateTime', 'LAT', 'LON', 'SOG', 'COG', 'Heading',  'IMO', 'VesselType', 'Status', 'Length','Width', 'Draft'])\n",
    "    df = df.dropna()\n",
    "    df = df[df['BaseDateTime'] >= datetime(2016,3,1,3)]\n",
    "    df.to_csv(os.path.join(str(year), '%s_AIS.csv' % str(year)))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-chorus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plotly(dataframe):\n",
    "    import plotly.express as px\n",
    "    fig = px.scatter_mapbox(dataframe,\n",
    "                        lat=dataframe.LAT,\n",
    "                        lon=dataframe.LON, color='SOG', mapbox_style=\"stamen-toner\")\n",
    "    fig.update_geos(\n",
    "        lataxis_range=[dataframe.LAT.min(),dataframe.LAT.max()], lonaxis_range=[dataframe.LON.min(), dataframe.LON.max()]\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-horizontal",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "download_AIS(2017, zones=list(range(4,10))) # zone 4 -> 9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-cylinder",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_AIS_to_CSV(year='2017', min_time_interval = 60) # subsampling and convert downloaded data into one csv   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-honor",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T13:19:26.572557Z",
     "start_time": "2021-02-16T13:19:24.981499Z"
    }
   },
   "outputs": [],
   "source": [
    "year = 2017\n",
    "df = pd.read_csv(Path(str(year),'%s_AIS.csv' % year))\n",
    "show_plotly(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-arrival",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T13:43:02.710461Z",
     "start_time": "2021-02-16T13:43:02.604523Z"
    }
   },
   "outputs": [],
   "source": [
    "show_plotly(df[(df['LON'] < -110) & (df['LAT'] < 70)]) # North Pacific"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
